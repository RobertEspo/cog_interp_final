---
title: "Interpreting Experience Mediates Recruitment of Early Intonational Cues to Sentence Modality: An Eye Tracking Study"
shorttitle: "Interpreting Experience and Early Intonational Cues"
author:
  - name: Robert Esposito
    corresponding: true
    email: rme70@rutgers.edu
    affiliations:
      name: "Rutgers University"
      department: Department of Spanish and Portuguese
      address: 15 Seminary Pl.
      city: New Brunswick
      region: NJ
      country: USA
      postal-code: 08901
author-note:
  # Disclosures condensed to one paragraph, but you can start a field with two line breaks to break them up: \n\nNew Paragraph
  disclosures:
    # Example: This study was registered at X (Identifier Y).
    study-registration: ~
    # Acknowledge and cite data/materials to be shared.
    data-sharing: ~
    # Example: This article is based on data published in [Reference].
    # Example: This article is based on the dissertation completed by [citation].  
    related-report: ~
    # Example: [Author name] has been a paid consultant for Corporation X, which funded this study.
    conflict-of-interest: The authors have no conflicts of interest to disclose.
    # Example: This study was supported by Grant [Grant Number] from [Funding Source].
    financial-support: ~
    # Example: The authors are grateful to [Person] for [Reason].
    gratitude: ~
    # Example. Because the authors are equal contributors, order of authorship was determined by a fair coin toss.
    authorship-agreements: ~
number-sections: false
abstract: "Accurately parsing intonation is crucial for identifying sentence modality (i.e., declarative versus interrogative utterances) in Spanish. Humans are believed to integrate linguistic information incrementally to make predictions about future content [@van2012prediction], and it follows that Spanish speakers would use early intonational cues to predict sentence modality, but this phenomena has not yet been investigated with on-line measures. This study uses eye-tracking to investigate L1 Spanish speakers' and L1 English L2 Spanish interpreters' sensitivity to early intonational information for predicting sentence modality. Importantly, the interpreters had more or less experience with interpreting interrogatives from Spanish to English. Participants completed a two-alternative forced choice task in which they identified if an orally-delivered utterance was an interrogative or not. Results of this study provide insight into understanding if either or both populations are sensitive to non-vital intonational information to predict sentence type. The findings of this study shed light on the incremental processing of intonational information as real-time sentence comprehension unfolds and provides information about which cues are recruited to make predictions."
keywords: [psycholinguistics, interpretation, intonation, second-language acquisition, Spanish]
floatsintext: true
bibliography: "./lit/cog_interp_final.bib"
format:
  apaquarto-docx: default
  apaquarto-html: default
  apaquarto-pdf:
    documentmode: man
---

```{r}
#| include: false
# load libs
library(here)
```

When listening to speech, humans are exposed to an acoustic signal that is seldom encoded in writing: fundamental frequency (F0). F0, modulated by how fast the vocal folds vibrate, is interpreted in human language as discrete pitch targets (high or low) and organized at the utterance-level to provide syntactic, pragmatic, and paralinguistic information into what we nominate intonation [@ladd2008intonational]. Both first language (L1) speakers and second language (L2) learners must accurately produce or perceive intonation to prevent communicative breakdowns. For example, distinguishing a sarcastic exclamation and a genuinely complimentary one in English (e.g., "How smart she is!") requires correct parsing of intonation, as the utterance is identical at both the lexical (word) and syntactic (word-order) levels [@zhou2019detecting].

Even more quotidian, Spanish declaratives and yes-no questions are similarly distinguished only at the level of intonation: *Mariano habla del tiempo* "Mariano talks about the weather" may variably be a statement or information-seeking (i.e., neutral) yes-no question depending solely on intonation. Traditionally, only the final F0 movement of the utterance is analyzed as providing the disambiguating cue. However, earlier intonational cues have been identified [@tomas1944manual; @quilis1993filologia; @verdugo2005aproximacion; @prieto2004search]. @face2007role determined in an off-line two-alternative forced choice task gating experiment that L1 Spain Spanish speakers can disambiguate sentence modality as early as the first word, which encompasses the first F0 peak.

As of yet, there has been no investigation to determine if the earlier cues are recruited as sentence processing unfolds to predict sentence modality. Theoretical models of brain function suggest that humans make continuous predictions about future events based on Bayesian inferences [@bar2007proactive; @lee2003hierarchical; @van2012prediction; @altmann1999incremental; @gruter2021prediction]. In other words, humans use prior knowledge, which in this case is the unconscious acquisition of the statistical probabilities of language, with real-time incoming evidence to update beliefs and expectations. As a trivial example, if one were to produce the utterance, "The boy will eat the...", the listener, upon hearing "eat", can narrow the hypothesis space based on prior experience to predict that a food item will appear downstream. It is expected that L1 Spanish and "proficient" (that is, native-like) L2 Spanish speakers would recruit intonational information as sentence processing unfolds to predict sentence modality. 

Furthermore, since these Bayesian-based models of the brain rely prior experience, it is predicted that experiential-factors will have a strong influence on the outcome, such that those who have more reliable success in predicting sentence modality based on the identified cues will pay more attention to those same cues in the future to make the same predictions [@roettger2019evidential]. Interpreters are trained to make use of prediction during interpreting [@dong2020attentional], and the same skills transfer to non-interpreting situations [@lozano2021interpreting]. Therefore, it is predicted that Spanish-English interpreters who more often interpret questions from Spanish to English, as opposed to English to Spanish, will more often recruit early intonational cues to make predictions on sentence modality. The results of the present study will shed light on the weighting of early intonational cues compared to the final F0 movement in their usefulness to predicting sentence modality during real-time processing [@roettger2019evidential], as well as the impact of experiential factors, like interpreting experience.

## Early Cues to Sentence Modality in Spanish

Broadly speaking, intonation can be used to signal speech act marking, information status, belief status, and politeness, among many other communicative functions [@prieto2015intonational; @best2019diversity; @arvaniti2020autosegmental; @cruttenden1997intonation; @cutler1997prosody; @dahan2015prosody; @gussenhoven2004phonology; @ladd2008intonational]. Relevant to this study, intonation may also encode sentence modality: @hirst1998survey found that approximately 70% of a sample of nearly 250 languages used the final pitch movement to signal interrogativity. Spanish is an example of such a language, in which an utterance e.g., 'Mariano habla del tiempo' *Mariano talks about the weather* may variably be a statement [@fig-declarative] or question [@fig-interrogative], differentiated only by intonation. Importantly, @hirst1998survey categorized languages using only the final F0 movement, and this has been the traditional analysis for Spanish as well [@tomas1974manual; @hualde2008intonation].

```{r}
#| label: fig-declarative
#| fig-cap: An example of a neutral declarative in Spanish, 'Mariana miraba la luna' (Mariana was looking at the moon).
knitr::include_graphics(
  here("assets", "declarative.bmp")
  )
```

Traditionally, only the last F0 movement is pointed to as the meaningful difference between the two sentence types [@tomas1974manual; @hualde2008intonation], but other non-final intonational cues have been identified [@quilis1993filologia; @verdugo2005aproximacion; @prieto2004search; @sensui1995perception; @sensui2003pilot; @face2004intonation; @face2005f0]. @face2005f0['s] off-line gating experiment unequivocally rejected the final F0 movement as the only cue for sentence modality: L1 Spain Spanish speakers can accurately determine sentence modality by the scaling (i.e., height) of the first F0 peak and the presence or absence of a medial pitch accent. In a follow-up off-line gating experiment [@face2007role], he found that these early cues hold dramatically less weight than the final F0 movement, which seems to "override" the sentence type interpretation regardless of which cues occurs to the left.

```{r}
#| label: fig-interrogative
#| fig-cap: An example of an information-seeking yes-no question in Spanish, 'Â¿Mariana miraba la luna?' (Was Mariana looking at the moon?).
knitr::include_graphics(
  here("assets", "interrogative.bmp")
  )
```

## Using Intonation to Predict

It seems unlikely that Spanish listeners should wait until the very end of an utterance to determine sentence modality. Humans constantly make predictions [@bar2007proactive; @lee2003hierarchical], and it follows that we also anticipate linguistic information [@van2012prediction]. Such a hypothesis has been supported across linguistic domains [e.g., @altmann1999incremental]. Prosody and intonation have traditionally received little attention [@cutler1997prosody], but the extant research has demonstrated that listeners integrate intonational information as sentence processing unfolds to make predictions of upcoming content [@esteve2020empathy; @grodner2010some; @kamide2003time; @crocker2010computational; @levy2008expectation]. Based on this evidence, it would be expected that L1 Spanish speakers do not wait until the final F0 movement to determine sentence modality, but instead integrate early intonational information to make predictions.

Although cues may be available, it is not given that a perceiver will integrate the cue in real-time processing to make predictions; that is, not all cues are weighted equally. @roettger2019evidential attempts to address this issue by introducing a computational model that proposes that the predictive value of an intonational cue is dependent on the prior reliability of the cue-to-function mapping and the likelihood of the mapping given the listener's most recent experiences. In a later series of mouse-tracking studies, @roettger2021positional found that L1 German speakers do not use the presence of absence of a prenuclear pitch accent to predict the discourse status of an upcoming referent, but some L1 American English speakers, who have the same cue with the same predictive power available, do. This research puts doubt on the claim that L1 Spanish speakers recruit early intonational cues, as opposed to waiting for the final F0 movement.

## Prediction in Interpreters

Interpreters are seen as expert predictors [@dong2020attentional; @setton2005pointing], and prediction (also referred to as "anticipation" in interpreting literature) is one of the most studied interpreting strategies in research [@pochhacker2016unity; @bartlomiejczyk2006strategies]. By taking advantage of the probabilistic nature of language, prediction training allows interpreters to reduce uncertainty, tantamount to reducing strain on processing capacities [@gile2009basic]. For example, @ko2024anticipation found that L1 Korean L2 English interpreting students understood the imperative to predict predicts when simultaneously interpreting Korean into English, attempting to do so about a third of the time. In an aligned corpus of German-Greek interpretations, @liontou2012anticipation found that, on average, one anticipation took places every 1.75 minutes. It has been made clear again and again that prediction is a prime strategy for interpreters, but there remains a dearth to investigate what cues can and are used to lead to accurate predictions, as well as what cues *aren't* used [@hodzik2023predictive].

The majority of research on prediction in interpreters has focused on semantics, pragmatics, and syntax [@zhao2022planning; @jorg2011bridging; @wilss1978syntactic]; that is, phonological phenomena have largely been ignored. @kohn1996strategic proposed that interpreters rely on all available cues to predict as much as possible, including prosodic features, but there is minimal experimental research making a connection between intonation and prediction. @gile1992predictable argued that German and Japanese interpreters may take advantage of predictable sentence endings cued by suprasegmental tonal stress, and @riccardi1997lingua suggested that prosodic features may help interpreters comprehend and predict during long or awkwardly-constructed parenthetical sentences. However, none of the previously mentioned researchers provided experimental evidence to support their claims. @seeber2001intonation, with an experimental design, investigated if a source text with a narrow F0 range with little variation (i.e., with minimal or no intonational cues) proves to negatively impact the interpreter's ability to predict the target verb from German into English compared to a more lively intonation. Contrary to the author's hypothesis, it was found that there was no significant difference between the two conditions. It should be noted that the author did not motivate the relationship between intonation and verb prediction and the participant pool consisted of only four subjects.

On the other hand, @lozano2020slowly, in an eye-tracking study, compared L1 English L2 Spanish learners with and without interpreting experience in their ability to anticipate a word's suffix based on the first syllable's prosodic pattern (i.e., lexical stress) and found that those with interpreting experience demonstrated greater prediction than those without. Although the authors did not analyze the contribution of each acoustic correlate of lexical stress (e.g., F0, intensity, and duration), it is clear that suprasegmental features can be recruited by interpreters, above and beyond the ability of non-interpreter bilinguals, to predict. There is a need to understand how an interpreter's unique profile contributes to their processing of intonational cues for predictive purposes. Although it is important to study interpreters in naturalistic settings, laboratory stimuli also provide useful information to inform hypotheses, as it has been found that interpreters extend language prediction to non-interpreting linguistic contexts [@lozano2023interpreting; @lozano2021interpreting].

Based on @roettger2021positional['s] model, it's expected that one's experiences will influence the predictive cue weights. Not only interpreting experience in general, but how often one predicts and how often that prediction is correct. In this case, it is expected that interpreters working in a Spanish-speaking law system most likely interpret questions from lawyers from Spanish to English (e.g., during an examination) more frequently, whereas those working in an English-speaking law system do not interpret questions as frequently. This would be an interesting situation to examine @roettger2021positional['s] model, which would predict that those who interpret questions from Spanish to English, as opposed to English to Spanish, would more readily recruit early intonational cues to predict sentence modality.

## Research Questions

Early intonational cues, such as first F0 peak and the presence or absence of a medial pitch accent[@tomas1944manual; @quilis1993filologia; @verdugo2005aproximacion; @prieto2004search; @face2005f0; @face2007role], allow for prediction of sentence modality to take place, but it is not yet clear if, as predicted by Bayesian models of the brain [@bar2007proactive; @lee2003hierarchical; @van2012prediction; @altmann1999incremental; @gruter2021prediction], L1 Spanish monolinguals or L1 Spanish L2 English late learners recruit such cues for prediction of sentence modality during on-line sentence processing. Experiential factors may also influence the degree to which the early intonational cues are recruited, such that interpreters with more experience interpreting questions from Spanish to English will show greater recruitment of earlier intonational cues.

The following research questions are experimental in nature:

1. Do L1 Spanish monolinguals recruit early intonational cues (i.e., first F0 peak and presence/absence of medial pitch accent) to predict sentence modality?

2. Do L1 English L2 Spanish late learners recruit early intonational cues (i.e., first F0 speak and presence/absence of medial pitch accent) to predict sentence modality?

3. Is the recruitment of the identified early intonational cues in L1 English L2 Spanish late learner interpreters dependent on experience interpreting questions from Spanish to English?

It is hypothesized that L1 Spanish speakers will recruit the early intonational cues to predict sentence type, reflected in greater target fixations [@face2007role]. As for L2 Spanish interpreters, it is hypothesized that they will also recruit the same cues to predict, but with a delay, as is typical for L2 learners [@corps2023two]. Furthermore, L2 Spanish interpreters with greater experience interpreting questions from Spanish to English (i.e., interpreters in Gibralatr) will show faster target fixations than those with less experience (i.e., interpreters in Madrid) [@roettger2021positional].

# Method

## Participants

Thirty L1 Spanish monolinguals, 30 L1 English L2 Spanish late learner interpreters in central Spain, and 30 L1 English L2 Spanish late learner interpreters in Gibraltar were recruited. The L1 Spanish monolinguals grew up in central Spain and have not spent more than 3 months outside of their city of origin. The L1 English participants were raised in a monolingual English environment in England and began the endeavor of learning Spanish after 12 years old.

## Materials

Aside from the experimental task, participants also completed a language background questionnaire. The survey collected information about participants' age of acquisition, cumulative language use, and current language use. For interpreters, it asked about how often they interpreted questions from Spanish to English. L2 participants were seen to have acquired Spanish primarily in the classroom, and all had experience living in Spain.

Using the visual-world eye-tracking paradigm, participants were tested to determine if they were able to accurately determine whether a sentence was a declarative or interrogative before the final syllable. There were 60 critical trials. 30 were declarative utterances and 30 were interrogative utterances.

All utterances consisted of an overt subject, a verb, and an object e.g., 'Mariano habla del tiempo' *Mariano talks about the weather*. The final word of the utterance always had penultimate stress so that the final pitch movement was not truncated with the nuclear pitch accent.

The utterances were all produced by a 25-year-old female L1 Spanish monolingual speaker from Madrid. In total, she produced 30 pairs of identical utterances for a total of 60 utterances: half of the utterances were produced as declaratives, and the other half were produced as interrogatives. Acoustic analysis confirmed that the first pitch peak of declarative utterances were always lower than the first pitch peak of the interrogative utterances. The declarative utterances were always produced with a medial pitch accent (e.g., on 'habla' in 'Mariano habla del tiempo'), whereas this pitch accent was absent in interrogative utterances. As expected, declarative utterances ended with a low boundary tone, whereas interrogative utterances ended with a high boundary tone.

The visual display accompanying the auditory stimuli had two areas of interest depicting identical images of two people. One of the people had a speech bubble with either '.' or '?'. An example trial is depicted in @fig-example-trial.

```{r}
#| label: fig-example-trial
#| fig-cap: Example of one trial.

knitr::include_graphics(
  here("assets", "example_trial.bmp")
  )
```

## Procedure

Prior to the eye-tracking task, all participants completed the LexTALE-ESP and the language background questionnaire. Once completed, the participant's dominant eye was determined by applying the Miles test [@miles1929ocular]. Only eye movements from the dominant eye were registered. Participants were seated in front of an Eyelink Pro 1000 eye-tracking system (approximately 80 cm). Participants wore headphones to hear audio stimuli. Participants were told that they would hear a number of sentences and must determine if it was a 'statement', which corresponded to the image with a '.', or a 'yes-no question', which corresponded to the image with a '?'. The placement of the visual stimuli were counterbalanced. Participants were asked to press either the left or right shift key that corresponded with the image on the left or right side of the screen that matched the utterance's sentence type, and they could respond at any point during the utterance.

At trial start, participants were exposed to a fixation cross for 500ms, after which the two images appeared for 200ms. At 700ms into the trial, the audio stimuli began to play. Once the audio finished, participants could respond using the shift keys. Once they responded, a grey box appeared on the screen in one of the four corners. After they looked at the box for 500ms, the next trial began.

Participants completed 4 practice trials before the experiment to familiarize themselves with the images and task. Participants were then exposed to a total of 90 (30 experimental and 60 filler) trials. The task took approximately 15 minutes to complete.

# Results

# Discussion

## Limitations and Future Directions

The present study proposal may suffer from various limitations. First, and most obvious, the target population is most likely extremely small and difficult to recruit.

Although the participants will be professionally working as interpreters, there is no measure of expertise in this study. It is important to distinguish between "professional" ability and "expertise", as one may make a living as an interpreter without being an expert. As such, such interpreters may not recruit the same strategies as expert interpreters.

The present study makes use of highly controlled laboratory speech as stimuli. As such, they may not be truly reflective of what is actually interpreted in court rooms. This may prove to be a problem since interpreters recruit extralinguistic information when interpreting [@gile2009basic]. For example, during an examination of a witness, the interpreter already has prior knowledge about the typical court structure and knows to expect that the lawyer will be asking questions. During the present experiment, the interpreters do not have that extralinguistic information available to them to use. It would be best to use real recordings of court rooms to determine if interpreters do exhibit prediction during yes-no questions, and if their rate of (accurate) prediction is correlated with their linguistic environment. 

The task used in the present study relies on metalinguistic knowledge instead of unconscious routines. That is, the participants are consciously aware of the task at hand, and may use different congitive processes than they would when simply interpreting. It would be much better to use semantics-based stimuli instead of outright asking participants if the utterance is an interrogative or not. However, creating such stimuli has proven problematic. Another option would be to have participants simply interpret a controlled Spanish source text with numerous information-seeking questions and neutral declaratives, similar to a cross-examination in court.

## Conclusion

# References

<!-- References will auto-populate in the refs div below -->

::: {#refs}
:::